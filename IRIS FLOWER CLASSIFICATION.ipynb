{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25924d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('iris.csv')\n",
    "\n",
    "# View the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cdec841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "setosa        50\n",
      "versicolor    50\n",
      "virginica     50\n",
      "Name: species, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get some basic information about the dataset\n",
    "print(data.info())\n",
    "\n",
    "# Check the distribution of the target classes\n",
    "print(data['species'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae841eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Preprocess the data\n",
    "X = data.drop('species', axis=1)\n",
    "y = data['species']\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1b281a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "22            4.6          3.6           1.0          0.2\n",
       "15            5.7          4.4           1.5          0.4\n",
       "65            6.7          3.1           4.4          1.4\n",
       "11            4.8          3.4           1.6          0.2\n",
       "42            4.4          3.2           1.3          0.2\n",
       "..            ...          ...           ...          ...\n",
       "71            6.1          2.8           4.0          1.3\n",
       "106           4.9          2.5           4.5          1.7\n",
       "14            5.8          4.0           1.2          0.2\n",
       "92            5.8          2.6           4.0          1.2\n",
       "102           7.1          3.0           5.9          2.1\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "789212fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2,\n",
       "       1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2,\n",
       "       1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1,\n",
       "       0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2,\n",
       "       1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1e19df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Random Forest Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "k-Nearest Neighbors (k-NN) Accuracy: 1.0\n",
      "k-Nearest Neighbors (k-NN) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "k-Nearest Neighbors (k-NN) Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "SVM Accuracy: 1.0\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "SVM Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Decision Tree Accuracy: 1.0\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Decision Tree Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Neural Networks (Multi-layer Perceptron) Accuracy: 1.0\n",
      "Neural Networks (Multi-layer Perceptron) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Neural Networks (Multi-layer Perceptron) Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Naive Bayes (GaussianNB) Accuracy: 1.0\n",
      "Naive Bayes (GaussianNB) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Naive Bayes (GaussianNB) Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "AdaBoost Accuracy: 1.0\n",
      "AdaBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "AdaBoost Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Logistic Regression Accuracy: 1.0\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nites\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\nites\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 1.0\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Gradient Boosting Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=label_encoder.classes_))\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\")\n",
    "\n",
    "# k-Nearest Neighbors (k-NN)\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"k-Nearest Neighbors (k-NN) Accuracy:\", accuracy_knn)\n",
    "print(\"k-Nearest Neighbors (k-NN) Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn, target_names=label_encoder.classes_))\n",
    "print(\"k-Nearest Neighbors (k-NN) Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(\"\")\n",
    "\n",
    "# SVM\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy:\", accuracy_svm)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=label_encoder.classes_))\n",
    "print(\"SVM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(\"\")\n",
    "\n",
    "# Decision Tree\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_dt)\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt, target_names=label_encoder.classes_))\n",
    "print(\"Decision Tree Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "print(\"\")\n",
    "\n",
    "# Neural Networks (Multi-layer Perceptron)\n",
    "nn_classifier = MLPClassifier(random_state=42)\n",
    "nn_classifier.fit(X_train, y_train)\n",
    "y_pred_nn = nn_classifier.predict(X_test)\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "print(\"Neural Networks (Multi-layer Perceptron) Accuracy:\", accuracy_nn)\n",
    "print(\"Neural Networks (Multi-layer Perceptron) Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nn, target_names=label_encoder.classes_))\n",
    "print(\"Neural Networks (Multi-layer Perceptron) Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nn))\n",
    "print(\"\")\n",
    "\n",
    "# Naive Bayes (GaussianNB)\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(\"Naive Bayes (GaussianNB) Accuracy:\", accuracy_nb)\n",
    "print(\"Naive Bayes (GaussianNB) Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb, target_names=label_encoder.classes_))\n",
    "print(\"Naive Bayes (GaussianNB) Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(\"\")\n",
    "\n",
    "# AdaBoost\n",
    "adaboost_classifier = AdaBoostClassifier(random_state=42)\n",
    "adaboost_classifier.fit(X_train, y_train)\n",
    "y_pred_adaboost = adaboost_classifier.predict(X_test)\n",
    "accuracy_adaboost = accuracy_score(y_test, y_pred_adaboost)\n",
    "print(\"AdaBoost Accuracy:\", accuracy_adaboost)\n",
    "print(\"AdaBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_adaboost, target_names=label_encoder.classes_))\n",
    "print(\"AdaBoost Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_adaboost))\n",
    "print(\"\")\n",
    "\n",
    "# Logistic Regression\n",
    "lr_classifier = LogisticRegression(random_state=42)\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "y_pred_lr = lr_classifier.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_lr)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=label_encoder.classes_))\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"\")\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "y_pred_gb = gb_classifier.predict(X_test)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_gb)\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gb, target_names=label_encoder.classes_))\n",
    "print(\"Gradient Boosting Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa404c02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
